{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "collaborative-survivor",
   "metadata": {},
   "source": [
    "# Plant Seedlings Image classification using CNNs in Keras\n",
    "\n",
    "## Data Description\n",
    "You are provided with a dataset of images of plant seedlings at various stages of grown. Each image has a filename that is its unique id. The dataset comprises 12 plant species. __The goal of the project is to create a classifier capable of determining a plant's species from a photo.__\n",
    "\n",
    "## Dataset\n",
    "The dataset can be download from Olympus.\n",
    "\n",
    "The data file names are:\n",
    "- images.npy\n",
    "- Label.csv\n",
    "\n",
    "The original files are from Kaggle. Due to the large volume of data, the images were converted to images.npy file and the labels\n",
    "are also put into the Labels.csv. So that you can work on the data/project seamlessly without worrying about the high data volume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-deployment",
   "metadata": {},
   "source": [
    "<!-- # Import necessary libraries.\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "data_path = '/content/drive/My Drive/Colab Notebooks/data/plant_seedlings/train.zip'\n",
    "!mkdir dataset\n",
    "\n",
    "# Extract the files from dataset to temp_train and temp_test folders (as the dataset is a zip file.)\n",
    "from zipfile import ZipFile\n",
    "with ZipFile(data_path, 'r') as zip:\n",
    " zip.extractall('./dataset')\n",
    "path = \"/content/dataset/*/*.*\" # The path to all images in training set. (* means include all folder\n",
    "s and files.)\n",
    "files = glob(path)\n",
    "trainImg = [] # Initialize empty list to store the image data as numbers.\n",
    "trainLabel = [] # Initialize empty list to store the labels of images\n",
    "j = 1\n",
    "num = len(files)\n",
    "# Obtain images and resizing, obtain labels\n",
    "for img in files:\n",
    " '''\n",
    " Append the image data to trainImg list.\n",
    " Append the labels to trainLabel list.\n",
    " '''\n",
    " print(str(j) + \"/\" + str(num), end=\"\\r\")\n",
    " trainImg.append(cv2.resize(cv2.imread(img), (128, 128))) # Get image (with resizing to 128x128)\n",
    " trainLabel.append(img.split('/')[-\n",
    "2]) # Get image label (folder name contains the class to which the image belong)\n",
    " j += 1\n",
    "trainImg = np.asarray(trainImg) # Train images set\n",
    "trainLabel = pd.DataFrame(trainLabel, columns=[\"Label\"]) # Train labels set\n",
    "print(trainImg.shape)\n",
    "print(trainLabel.shape)\n",
    "trainLabel.to_csv('Labels.csv', index=False)\n",
    "np.save('plantimages', trainImg)\n",
    "/h -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-secretariat",
   "metadata": {},
   "source": [
    "The following code was used to convert the large dataset of images to numpy array:\n",
    "\n",
    "`# Import necessary libraries.\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "data_path = '/content/drive/My Drive/Colab Notebooks/data/plant_seedlings/train.zip'\n",
    "!mkdir dataset`\n",
    "\n",
    "`# Extract the files from dataset to temp_train and temp_test folders (as the dataset is a zip file.)\n",
    "from zipfile import ZipFile\n",
    "with ZipFile(data_path, 'r') as zip:\n",
    " zip.extractall('./dataset')\n",
    "path = \"/content/dataset/*/*.*\" # The path to all images in training set. (* means include all folder\n",
    "s and files.)\n",
    "files = glob(path)\n",
    "trainImg = [] # Initialize empty list to store the image data as numbers.\n",
    "trainLabel = [] # Initialize empty list to store the labels of images\n",
    "j = 1\n",
    "num = len(files)`\n",
    "\n",
    "`# Obtain images and resizing, obtain labels\n",
    "for img in files:\n",
    " '''\n",
    " Append the image data to trainImg list.\n",
    " Append the labels to trainLabel list.\n",
    " '''\n",
    " print(str(j) + \"/\" + str(num), end=\"\\r\")\n",
    " trainImg.append(cv2.resize(cv2.imread(img), (128, 128))) # Get image (with resizing to 128x128)\n",
    " trainLabel.append(img.split('/')[-\n",
    "2]) # Get image label (folder name contains the class to which the image belong)\n",
    " j += 1\n",
    "trainImg = np.asarray(trainImg) # Train images set\n",
    "trainLabel = pd.DataFrame(trainLabel, columns=[\"Label\"]) # Train labels set\n",
    "print(trainImg.shape)\n",
    "print(trainLabel.shape)\n",
    "trainLabel.to_csv('Labels.csv', index=False)\n",
    "np.save('plantimages', trainImg)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-refund",
   "metadata": {},
   "source": [
    "## Context\n",
    "Can you differentiate a weed from a crop seedling?\n",
    "The ability to do so effectively can mean better crop yields and better stewardship of the environment.\n",
    "The Aarhus University Signal Processing group, in collaboration with University of Southern Denmark, has\n",
    "recently released a dataset containing images of unique plants belonging to 12 species at several growth stages\n",
    "\n",
    "\n",
    "## Objective\n",
    "To implement the techniques learnt as a part of the course.\n",
    "Learning Outcomes:\n",
    "- Pre-processing of image data.\n",
    "- Visualization of images.\n",
    "- Building CNN.\n",
    "- Evaluate the Model.\n",
    "- The motive of the project is to make the learners capable to handle images/image classification problems, during this\n",
    "process you should also be capable to handle real image files, not just limited to a numpy array of image pixels.\n",
    "Guide to solve the project seamlessly:\n",
    "Here are the points which will help you to solve the problem efficiently:\n",
    "- Read the problem statement carefully from start to end (including the note at the end). The highlighted part in the\n",
    "attached problem statement should not be missed.\n",
    "- Download the dataset from the Olympus platform.\n",
    "- Upload the \"images.npy\" and “Labels.csv” file to google drive.\n",
    "- Then you can use the dataset path in the Google Colab notebook to do further steps related to project problem\n",
    "statement.\n",
    "- You can set runtime type to “GPU” in Google Colab, so that the code will run faster as you will be using CNN to fit your\n",
    "model.\n",
    "\n",
    "## Steps and tasks\n",
    "1. Import the libraries, load dataset, print shape of data, visualize the images in dataset. (5 Marks)\n",
    "2. Data Pre-processing: (15 Marks)\n",
    "    1. Normalization.\n",
    "    1. Gaussian Blurring.\n",
    "    1. Visualize data after pre-processing.\n",
    "3. Make data compatible: (10 Marks)\n",
    "    1. Convert labels to one-hot-vectors.\n",
    "    1. Print the label for y_train[0].\n",
    "    1. Split the dataset into training, testing, and validation set. (Hint: First split images and labels into training and testing set with test_size = 0.3. Then further split test data into test and validation set with test_size = 0.5)\n",
    "   1. Check the shape of data, Reshape data into shapes compatible with Keras models if it’s not already. If it’s already in the compatible shape, then comment in the notebook that it’s already in compatible shape.\n",
    "4. Building CNN: (15 Marks)\n",
    "    1. Define layers.\n",
    "    1. Set optimizer and loss function. (Use Adam optimizer and categorical crossentropy.)\n",
    "5. Fit and evaluate model and print confusion matrix. (10 Marks)\n",
    "6. Visualize predictions for x_test[2], x_test[3], x_test[33], x_test[36], x_test[59]. (5 Marks)\n",
    "\n",
    "## Note\n",
    "- Download the train images from the Olympus Platform.\n",
    "- Do not download the dataset from Kaggle, as:\n",
    "    - The dataset is big.\n",
    "    - The dataset has 2 files for train and test images, but the labels are only for the train file. Test file has no labels associated with it. So, when you want to know the accuracy of model on test images, there’s no way to measure it. That’s why the data provided to you on Olympus has only train images and their labels. For our purpose we use this for our training and testing and validation purpose.\n",
    "\n",
    "Happy Learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-donor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
